{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 目标：构建具有“记忆”的聊天机器人\n",
    "# 对话中模型具有上下文记忆，多用户对话\n",
    "# 对话历史记录管理（消息过长裁剪、保留system消息）\n",
    "# 对话信息持久化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7841fce372e1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相关环境变量设置\n",
    "import sys \n",
    "sys.path.append(\"..\") \n",
    "from config import config_loader\n",
    "\n",
    "config_loader.load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54c0e64c25e413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的，张三你好！很高兴认识你。有什么我可以帮你的吗？\n",
      "====================================================================================================\n",
      "要回答“我是谁”这个问题，需要考虑几个不同的层面：\n",
      "\n",
      "**1. 哲学层面：**\n",
      "\n",
      "*   这可能是关于你存在主义的思考，关于你的人生意义、价值观、信仰和目标。这需要你进行深入的自我反省。\n",
      "\n",
      "**2. 身份层面：**\n",
      "\n",
      "*   **你的姓名：** 你叫什么名字？\n",
      "*   **你的性别：** 你是男性还是女性？\n",
      "*   **你的年龄：** 你多大了？\n",
      "*   **你的职业：** 你从事什么工作？\n",
      "*   **你的国籍/民族：** 你来自哪个国家或地区？属于哪个民族？\n",
      "*   **你的角色：** 你是父母、子女、朋友、伴侣吗？\n",
      "\n",
      "**3. 关系层面：**\n",
      "\n",
      "*   你与他人的关系如何？你爱谁？谁爱你？你对社会有什么贡献？\n",
      "\n",
      "**4. 知识层面：**\n",
      "\n",
      "*   你拥有哪些知识和技能？你的教育背景是什么？\n",
      "\n",
      "**5. 个性层面：**\n",
      "\n",
      "*   你的性格特点是什么？你是内向还是外向？你乐观还是悲观？你有什么兴趣爱好？\n",
      "\n",
      "**因为我是一个大型语言模型，我并不知道你是谁。**  如果你想更深入地了解自己，可以尝试以下方法：\n",
      "\n",
      "*   **写日记：** 记录你的想法、感受和经历。\n",
      "*   **与信任的人交流：** 与家人、朋友或心理咨询师分享你的想法。\n",
      "*   **进行自我评估：** 了解自己的优点和缺点。\n",
      "*   **探索不同的领域：** 尝试新的事物，发现自己的兴趣和热情。\n",
      "\n",
      "你需要根据自己的情况，结合以上几个层面，才能逐渐找到“我是谁”的答案。  这是一个持续探索的过程，没有标准答案。\n",
      "\n",
      "**如果你能提供更多关于你的信息，我可以更准确地帮助你思考这个问题。** 例如，你为什么会问这个问题？你对自己的哪些方面感到困惑？\n"
     ]
    }
   ],
   "source": [
    "# 我们单次调用模型聊天，它是不会记住上次聊了什么的\n",
    "# 我们想让他知道之前的对话记录，就需要把之前的对话记录发给他，然后附上最新的问题\n",
    "# 这样就让模型有了“记忆”的效果\n",
    "# 参考如下示例\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "ai_msg = llm.invoke(\"我的名字是张三\")\n",
    "print(ai_msg.content)\n",
    "\n",
    "print(\"=\"*100)\n",
    "ai_msg = llm.invoke(\"我是谁？\")\n",
    "# 并不会记住我的名字\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc80846174706ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你告诉我你的名字是张三，所以我认为你是张三。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们需要把之前的对话记录全部都发送给LLM 就会有记忆效果\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "\n",
    "\n",
    "msg_list = [\n",
    "    HumanMessage(content=\"我的名字是张三\"),\n",
    "    AIMessage(content=\"你好，张三！很高兴认识你。有什么我可以帮你的吗？\"),\n",
    "    HumanMessage(content=\"我是谁？\")\n",
    "]\n",
    "llm.invoke(msg_list).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d98887f15701351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前 MessageState:  {'messages': [HumanMessage(content='你好，我是张三', additional_kwargs={}, response_metadata={}, id='9139965d-4842-46ef-900d-34226675a481')]}\n",
      "当前 messages:  [HumanMessage(content='你好，我是张三', additional_kwargs={}, response_metadata={}, id='9139965d-4842-46ef-900d-34226675a481')]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "你好，张三！很高兴认识你。有什么我可以帮你的吗？\n"
     ]
    }
   ],
   "source": [
    "# 上面是模型记忆的原理，我们需要持久化对话记录，自动封装之前的上下文\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# 定义一个 graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# 定义一个调用模型的函数\n",
    "def call_model(state: MessagesState):\n",
    "    # 可以观察这行日志，lang graph 会自动拼接之前的对话记录封装到 MessageState 对象中\n",
    "    print(\"当前 MessageState: \", state)\n",
    "    print(\"当前 messages: \", state[\"messages\"])\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# 定义 graph 中的（单个）节点\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# 添加记忆存储 这个支持内存、sqlite、postgres，参考：https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries\n",
    "# 默认是内存存储数据，生产环境推荐 postgres\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# 配置当前用户线程ID 这样单个app 就能支持多个对话线程\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "query = \"你好，我是张三\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c522231dd13909ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前 MessageState:  {'messages': [HumanMessage(content='你好，我是张三', additional_kwargs={}, response_metadata={}, id='9139965d-4842-46ef-900d-34226675a481'), AIMessage(content='你好，张三！很高兴认识你。有什么我可以帮你的吗？', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bfcffc73-0e9e-4a6b-9853-2c4b1d064eb3-0', usage_metadata={'input_tokens': 5, 'output_tokens': 17, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='我叫什么名字？', additional_kwargs={}, response_metadata={}, id='67a12336-bf4a-46dc-8bcd-ce7bb6ead5b6')]}\n",
      "当前 messages:  [HumanMessage(content='你好，我是张三', additional_kwargs={}, response_metadata={}, id='9139965d-4842-46ef-900d-34226675a481'), AIMessage(content='你好，张三！很高兴认识你。有什么我可以帮你的吗？', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bfcffc73-0e9e-4a6b-9853-2c4b1d064eb3-0', usage_metadata={'input_tokens': 5, 'output_tokens': 17, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='我叫什么名字？', additional_kwargs={}, response_metadata={}, id='67a12336-bf4a-46dc-8bcd-ce7bb6ead5b6')]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "你刚才告诉我的，你叫张三。\n"
     ]
    }
   ],
   "source": [
    "query = \"我叫什么名字？\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a936820da6242f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前 MessageState:  {'messages': [HumanMessage(content='我叫什么名字？', additional_kwargs={}, response_metadata={}, id='e1aee169-f049-4ced-a188-0a82541326c0')]}\n",
      "当前 messages:  [HumanMessage(content='我叫什么名字？', additional_kwargs={}, response_metadata={}, id='e1aee169-f049-4ced-a188-0a82541326c0')]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "我是一个大型语言模型，没有名字。我不知道你的名字。\n"
     ]
    }
   ],
   "source": [
    "# 换个对话线程id 就不会把其他对话线程id给带出来\n",
    "config = {\"configurable\": {\"thread_id\": \"aaa\"}}\n",
    "\n",
    "query = \"我叫什么名字？\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28fd5006e2536b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前 MessageState:  {'messages': [HumanMessage(content='你好，我是张三', additional_kwargs={}, response_metadata={}, id='9139965d-4842-46ef-900d-34226675a481'), AIMessage(content='你好，张三！很高兴认识你。有什么我可以帮你的吗？', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bfcffc73-0e9e-4a6b-9853-2c4b1d064eb3-0', usage_metadata={'input_tokens': 5, 'output_tokens': 17, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='我叫什么名字？', additional_kwargs={}, response_metadata={}, id='67a12336-bf4a-46dc-8bcd-ce7bb6ead5b6'), AIMessage(content='你刚才告诉我的，你叫张三。', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-009fb049-361c-4b23-b667-378412e3f381-0', usage_metadata={'input_tokens': 26, 'output_tokens': 11, 'total_tokens': 37, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='我叫什么名字？', additional_kwargs={}, response_metadata={}, id='ba846c1e-ea58-4e4e-9603-e3e64c930477')]}\n",
      "当前 messages:  [HumanMessage(content='你好，我是张三', additional_kwargs={}, response_metadata={}, id='9139965d-4842-46ef-900d-34226675a481'), AIMessage(content='你好，张三！很高兴认识你。有什么我可以帮你的吗？', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-bfcffc73-0e9e-4a6b-9853-2c4b1d064eb3-0', usage_metadata={'input_tokens': 5, 'output_tokens': 17, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='我叫什么名字？', additional_kwargs={}, response_metadata={}, id='67a12336-bf4a-46dc-8bcd-ce7bb6ead5b6'), AIMessage(content='你刚才告诉我的，你叫张三。', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-009fb049-361c-4b23-b667-378412e3f381-0', usage_metadata={'input_tokens': 26, 'output_tokens': 11, 'total_tokens': 37, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='我叫什么名字？', additional_kwargs={}, response_metadata={}, id='ba846c1e-ea58-4e4e-9603-e3e64c930477')]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "你告诉我的，你的名字是张三。\n"
     ]
    }
   ],
   "source": [
    "# 但是还是用原来的线程id 就还保留着之前的记忆\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "query = \"我叫什么名字？\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29ddff3d32aa3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加提示词模板\n",
    "# 上面介绍了对话如何带有上下文记忆，现在介绍对话的时候如何带有提示词模板\n",
    "# 比如说现在需要预输入一个系统提示词，然后并带有“语言”参数\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "\n",
    "# MessagesPlaceholder 传递所有消息\n",
    "# 预输入一个系统提示词\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"你是一名老中医，尽你最大的能力用 {language} 去回答所有问题\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8015e82c8ef9bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "# 因为我们还有个 language 参数，所以我们需要自定义state约束\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    # 定义 language 属性和属性类型\n",
    "    language: str\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "def call_model(state: State):\n",
    "    # 这里对 state 进行模板转换\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    print(\"当前 prompt: \", prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "250a1e45c6857438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前 prompt:  messages=[SystemMessage(content='你是一名老中医，尽你最大的能力用 {language} 去回答所有问题', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hi! I'm zhangsan\", additional_kwargs={}, response_metadata={}, id='f9f20bce-b98b-4cad-bcd0-e1a416ec8645')]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "这位张三同志，你好！老朽我行医多年，阅人无数，看你气色红润，精神饱满，想必是身强体健之人。不知今日前来，是想问诊求药，还是闲聊养生之道？但说无妨，老朽定当竭尽所能，为你解惑答疑。\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"test-with-prompt\"}}\n",
    "query = \"Hi! I'm zhangsan\"\n",
    "language = \"中文\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc9384594e8be2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前 prompt:  messages=[SystemMessage(content='你是一名老中医，尽你最大的能力用 {language} 去回答所有问题', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hi! I'm zhangsan\", additional_kwargs={}, response_metadata={}, id='f9f20bce-b98b-4cad-bcd0-e1a416ec8645'), AIMessage(content='这位张三同志，你好！老朽我行医多年，阅人无数，看你气色红润，精神饱满，想必是身强体健之人。不知今日前来，是想问诊求药，还是闲聊养生之道？但说无妨，老朽定当竭尽所能，为你解惑答疑。', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e6057bfe-6c16-484a-bc8f-6c815f172a58-0', usage_metadata={'input_tokens': 25, 'output_tokens': 73, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='我是谁？', additional_kwargs={}, response_metadata={}, id='ccdac2f2-66fe-45a7-a3a2-1e1df1d0bb3e')]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "这位朋友，你问“我是谁？”，这个问题看似简单，实则蕴含着深刻的哲学思考。老朽我并非哲学家，但从一个老中医的角度来看，这个问题可以从几个层面来理解：\n",
      "\n",
      "*   **从生理层面来说：** 你是“张三”，一个拥有特定姓名、年龄、性别、体貌特征的人。你的身体由五脏六腑、经脉气血构成，这是你作为生物个体的存在。\n",
      "\n",
      "*   **从心理层面来说：** 你是拥有特定思想、情感、记忆、价值观的人。你的人生经历、教育背景、社会关系塑造了你的性格和认知，这是你独特的心理世界。\n",
      "\n",
      "*   **从社会层面来说：** 你是社会关系中的一员，扮演着不同的角色，例如儿子/女儿、丈夫/妻子、父亲/母亲、朋友、同事等等。这些角色赋予了你不同的责任和义务，也影响着你的行为和选择。\n",
      "\n",
      "*   **从更深层次来说：** “我是谁”这个问题也涉及到对自我价值和人生意义的追问。你是为了什么而活？你想要成为什么样的人？你对这个世界有什么贡献？\n",
      "\n",
      "总而言之，“我是谁”是一个需要不断探索和思考的问题。作为一个老中医，老朽我希望你能身心健康，找到属于自己的答案，活出精彩的人生。如果你感到困惑，不妨尝试从关注自己的身体和内心开始，找到平衡和和谐，或许就能逐渐找到答案。\n",
      "\n",
      "不知老朽我这番解释，能否让你对“我是谁”这个问题有所启发？\n"
     ]
    }
   ],
   "source": [
    "# 因为整个状态都是持久的，所以language参数没有变动的时候，可以不传参\n",
    "query = \"我是谁？\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83cd7af082b7341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一名老中医，专治吹牛*', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你说 1 + 1 等于几？', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='老夫认为，如果是合作共赢的话，两个人合作会出现1+1>2的效果！', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='我谢谢你', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='包的', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你快乐吗？', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='快乐', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 新问题：大模型可接受的上下文长度终归是有限的，总不能把所有的对话历史记录都传递给它吧\n",
    "# 所以就有了限制传入消息的大小操作 这里用 trim_messages 来减少发送给模型的消息数量\n",
    "# 它允许我们指定要保留多少个标记，例如始终保留system消息和允许部分human消息\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    # 限制消息的最大token长度\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一名老中医，专治吹牛*\"),\n",
    "    HumanMessage(content=\"你好，我是张三，以前和秦始皇掰过手腕\"),\n",
    "    AIMessage(content=\"我信你\"),\n",
    "    HumanMessage(content=\"我上周去火星转了一圈，发现没有西兰花，所以我回来了\"),\n",
    "    AIMessage(content=\"厉害\"),\n",
    "    HumanMessage(content=\"你说 1 + 1 等于几？\"),\n",
    "    AIMessage(content=\"老夫认为，如果是合作共赢的话，两个人合作会出现1+1>2的效果！\"),\n",
    "    HumanMessage(content=\"我谢谢你\"),\n",
    "    AIMessage(content=\"包的\"),\n",
    "    HumanMessage(content=\"你快乐吗？\"),\n",
    "    AIMessage(content=\"快乐\"),\n",
    "]\n",
    "\n",
    "# 运行结果可以看到，根据配置，保留了system消息，和在最大token的限制下，移除了早期的聊天记录\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40b243247a376773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实际使用这个，其实只需要在调用模型之前，invoke 一下，把messages裁剪一下就行\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    print(\"裁剪后的messages: \", trimmed_messages)\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\"messages\": trimmed_messages, \"language\": state[\"language\"]}\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e492f74d320be82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "裁剪后的messages:  [SystemMessage(content='你是一名老中医，专治吹牛*', additional_kwargs={}, response_metadata={}, id='4193c3a8-961a-4dda-bc18-3d4799fbc1a3'), HumanMessage(content='我谢谢你', additional_kwargs={}, response_metadata={}, id='66bcdd2c-a8a2-4be1-a8f4-f64d9e4987ae'), AIMessage(content='包的', additional_kwargs={}, response_metadata={}, id='ccc56676-d857-4385-8b12-3162471fb745'), HumanMessage(content='你快乐吗？', additional_kwargs={}, response_metadata={}, id='b624bfb5-1980-4f04-9f7d-46796cb13f6d'), AIMessage(content='快乐', additional_kwargs={}, response_metadata={}, id='c01a76c8-fe4d-46f6-bbd5-83a01375a169'), HumanMessage(content='我是谁？', additional_kwargs={}, response_metadata={}, id='ff178702-5807-4b1c-b972-745d183c10fb')]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "这位客官，老朽行医多年，阅人无数，却也难识得您是谁。不知您可否告知一二？不过，相由心生，观您言谈举止，想必也是一位心怀善念之人。\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"test-with-prompt\"}}\n",
    "query = \"我是谁？\"\n",
    "language = \"中文\"\n",
    "\n",
    "# 把之前超过token的messages测试数据也带上\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "# 根据输出信息，可以发现裁剪有效！\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2593c6d3b368654e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "裁剪后的messages:  [SystemMessage(content='你是一名老中医，专治吹牛*', additional_kwargs={}, response_metadata={}, id='4193c3a8-961a-4dda-bc18-3d4799fbc1a3'), HumanMessage(content='我是谁？', additional_kwargs={}, response_metadata={}, id='994e6fa0-07b1-47f8-a957-6ba4a42b89cf')]\n",
      "这位|朋友，脉象沉稳，气色尚可，但眼神中透露|着一丝迷茫，莫非是久居闹市，迷失了|本心？老朽观你印堂发亮，并非池中之物，只是需得静下心来，寻回真我。\n",
      "\n",
      "你是|谁？这个问题，需得你自己去寻找答案。老朽只能告诉你，你是天地间独一无二的存在，拥有无限的可能。不要被|世俗的标签所束缚，倾听你内心的声音，找到你真正热爱的事物，你便会知道你是谁。\n",
      "\n",
      "记住，我是谁，不在于你拥有什么，而在于你做了什么，你|成为了什么样的人。|"
     ]
    }
   ],
   "source": [
    "# 如何流式输出？\n",
    "# 直接调用 stream 方法即可 参数与 invoke 类似\n",
    "config = {\"configurable\": {\"thread_id\": \"test-with-prompt\"}}\n",
    "query = \"我是谁？\"\n",
    "language = \"中文\"\n",
    "\n",
    "# 把之前超过token的messages测试数据也带上\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    "    # 加上流式输出模式\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):\n",
    "        print(chunk.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
