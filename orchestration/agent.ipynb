{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "# 目标 让 llm 具有调用工具的能力，也就是所谓的 agent",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 安装依赖\n",
    "%pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite"
   ],
   "id": "85a62edb50c78d75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 相关环境变量设置\n",
    "import config_loader\n",
    "\n",
    "config_loader.load_env()"
   ],
   "id": "515d4eb5e0087479",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "\n",
    "# 测试工具是否可以正常使用\n",
    "search_results = search.invoke(\"北京未来一周的天气情况\")\n",
    "print(search_results)\n",
    "\n",
    "# 工具可以都放到一个列表中 给模型调用\n",
    "tools = [search]"
   ],
   "id": "acc469d86cdd511b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 让 llm 使用工具\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "# 定义大模型\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "# 给该大模型绑定工具\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# 测试普通消息\n",
    "response = llm_with_tools.invoke([HumanMessage(content='你好呀！')])\n",
    "print(f'普通消息调用结果：{response.content}')\n",
    "print(f\"工具调用信息：{response.tool_calls}\", )"
   ],
   "id": "6c9f2fee4c18a254",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "response = llm_with_tools.invoke(\"北京未来一周天气\")\n",
    "# 可以看到这个是空的\n",
    "print(f\"调用工具消息结果：{response.content}\" )\n",
    "# 这个不是调用工具的结果，而是大模型告诉我们要调用这个工具 所以需要创建代理\n",
    "print(f\"工具调用信息：{response.tool_calls}\")"
   ],
   "id": "36a80eac2cd4c849",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 创建 agent\n",
    "agent_executor = create_react_agent(llm, tools)\n",
    "\n",
    "# 看看不需要工具时候的响应\n",
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"你好~\")]})\n",
    "\n",
    "response[\"messages\"]"
   ],
   "id": "28c990a81e37bde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 测试工具调用\n",
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"北京今天天气情况\")]})\n",
    "\n",
    "print(type(response))\n",
    "response[\"messages\"]"
   ],
   "id": "8e865d03d9d1526b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 流式传输 显式实时进度\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"今天北京天气怎么样？\")]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ],
   "id": "7a2d21f83d9b7a0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# langchain-core>=0.3.37 的话 也可以添加 stream_mode=\"messages\"\n",
    "for step, metadata in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"北京今天天气怎么样\")]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):\n",
    "        print(text, end=\"|\")"
   ],
   "id": "aee5bda442c57751",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# agent 添加记忆\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "# 就是传参的时候 多一个 checkpointer 参数\n",
    "agent_executor = create_react_agent(llm, tools, checkpointer=memory)\n",
    "\n",
    "# 设置对话线程\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"我的名字是张三\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ],
   "id": "39bb8c21ef1f6ca3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 测试记忆\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"我的名字是什么？\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ],
   "id": "f523090c5610b89",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
